import numpy as np


class UCBVI(object):
    def __init__(self, env, K):
        self.env = env
        self.K = K
        self.delta = 1 / 3
        self.buffer = {h: [] for h in range(self.env.epLen)}
        self.Nxay = {(s, a, s_): 0.0 for s in self.env.states.keys() for a in range(self.env.nAction) \
                     for s_ in self.env.states.keys()}
        self.Nxa = {(s, a): 0.0 for s in self.env.states.keys() for a in range(self.env.nAction)}
        self.N_ = {(h, s, a): 0.0 for h in range(self.env.epLen + 1) for s in self.env.states.keys() \
                   for a in range(self.env.nAction)}
        self.P = {(s, a, s_): 0.0 for s in self.env.states.keys() for a in \
                  range(self.env.nAction) for s_ in self.env.states.keys()}
        self.Q = {(h, s, a): self.env.epLen + 1 for h in range(self.env.epLen) for s in self.env.states.keys() \
                  for a in range(self.env.nAction)}

    def update_buffer(self, s, a, r, s_, h):
        self.buffer[h].append((s, a, r, s_, h))

    def act(self, s, h):
        x = np.array([self.Q[(h, s, a)] for a in range(self.env.nAction)])
        return self.env.argmax(x)

    def learn(self, k):
        self.update_counts(k)
        self.update_probability_transition()
        self.update_value_functions(k)

    def update_probability_transition(self):
        for s in self.env.states.keys():
            for a in range(self.env.nAction):
                if self.Nxa[(s, a)] > 0:
                    for s_ in self.env.states.keys():
                        self.P[(s, a, s_)] = (self.Nxay[(s, a, s_)]) / (self.Nxa[(s, a)])

    def update_counts(self, k):
        for d in self.buffer.values():
            # print(d)
            # print(k)
            # print(d[k][0])
            s, a, r, s_, h = d[k][0], d[k][1], d[k][2], d[k][3], d[k][4]
            if s_ != None:
                self.Nxay[(s, a, s_)] += 1
            self.Nxa[(s, a)] += 1
            self.N_[(h, s, a)] += 1

    def update_value_functions(self, k):
        V = {(h, s): 0.0 for s in self.env.states.keys() for h in range(self.env.epLen + 1)}
        for h in range(self.env.epLen - 1, -1, -1):
            # print(h)
            for s in self.env.states.keys():
                for a in range(self.env.nAction):
                    if self.Nxa[(s, a)] > 0:
                        # bonus = self.bonus_1(s,a)
                        PV = self.multiplyDictionaries(s, a, h, V)
                        bonus = self.bonus_2(s, a, h, V)
                        self.Q[(h, s, a)] = min(min(self.Q[(h, s, a)], self.env.epLen),
                                                self.env.R[(s, a)][0] + PV + bonus)
                    else:
                        self.Q[(h, s, a)] = self.env.epLen
                V[(h, s)] = max(np.array([self.Q[(h, s, a)] for a in range(self.env.nAction)]))

    def bonus_1(self, s, a):
        T = self.K * self.env.epLen
        L = np.log(5 * self.env.nState * self.env.nAction * T / self.delta)
        return 7 * env.epLen * L * np.sqrt(1 / self.Nxa[(s, a)])

    def bonus_2(self, s, a, h, V):
        temp = []
        T = self.K * self.env.epLen
        L = np.log(5 * self.env.nState * self.env.nAction * T / self.delta)
        for s_ in self.env.states.keys():
            c = V[(h + 1, s_)] * self.P[(s, a, s_)]
            temp.append(c)
        var = np.var(temp)
        # print(var)
        first = np.sqrt(8 * L * var / self.Nxa[(s, a)])
        second = 14 * self.env.epLen * L / (3 * self.Nxa[(s, a)])
        # third = np.sqrt(8*sums/self.Nxa[(s,a)])
        return first + second

    def multiplyDictionaries(self, s, a, h, V):
        sums = 0.0
        for s_ in self.env.states.keys():
            sums += V[(h + 1, s_)] * self.P[(s, a, s_)]
        return sums